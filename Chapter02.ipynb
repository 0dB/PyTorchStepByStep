{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn PyTorch Step-by-Step: A Beginner's Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import requests\n",
    "\n",
    "folders = ['data_generation', 'data_preparation', 'model_configuration', 'model_training']\n",
    "filenames = ['simple_linear_regression.py', 'v0.py', 'v0.py', 'v0.py']\n",
    "\n",
    "base_url = 'https://raw.githubusercontent.com/dvgodoy/PyTorchStepByStep/master/'\n",
    "\n",
    "for folder, filename in zip(folders, filenames):\n",
    "    try:\n",
    "        os.mkdir(folder)\n",
    "    except OSError as e:\n",
    "        e.errno\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "            \n",
    "    if os.path.exists('/colabtools'):\n",
    "        path = os.path.join(folder, filename)\n",
    "        url = '{}{}'.format(base_url, path)\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(path, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rethinking the Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs data generation - so we do not need to copy code here\n",
    "%run -i data_generation/simple_linear_regression.py\n",
    "\n",
    "# Runs the first two parts of the sequence: data preparation and model configuration\n",
    "%run -i data_preparation/v0.py\n",
    "%run -i model_configuration/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_training/v0.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Sets model to TRAIN mode\n",
    "    model.train()\n",
    "\n",
    "    # Step 1 - Computes our model's predicted output - forward pass\n",
    "    # No more manual prediction!\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    # Step 2 - Computes the loss\n",
    "    loss = loss_fn(y_train_tensor, yhat)\n",
    "\n",
    "    # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4 - Updates parameters using gradients and the learning rate\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-Order Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "def cube(x):\n",
    "    return x ** 3\n",
    "\n",
    "def fourth_power(x):\n",
    "    return x ** 4\n",
    "\n",
    "# and so on and so forth..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_exponentiation(x, exponent):\n",
    "    return x ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeleton_exponentiation(x):\n",
    "    return x ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exponent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/projects/PyTorchStepByStep/model_configuration/v0.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mskeleton_exponentiation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/PyTorchStepByStep/model_configuration/v0.py\u001b[0m in \u001b[0;36mskeleton_exponentiation\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mskeleton_exponentiation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mexponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'exponent' is not defined"
     ]
    }
   ],
   "source": [
    "skeleton_exponentiation(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponentiation_builder(exponent):\n",
    "    def skeleton_exponentiation(x):\n",
    "        return x ** exponent\n",
    "\n",
    "    return skeleton_exponentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.exponentiation_builder.<locals>.skeleton_exponentiation(x)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_function = exponentiation_builder(2)\n",
    "\n",
    "returned_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_function(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "square = exponentiation_builder(2)\n",
    "cube = exponentiation_builder(3)\n",
    "fourth_power = exponentiation_builder(4)\n",
    "\n",
    "# and so on and so forth..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def perform_train_step(x, y):\n",
    "        # Sets model to TRAIN mode\n",
    "        model.train()\n",
    "        \n",
    "        # Step 1 - Computes our model's predicted output - forward pass\n",
    "        yhat = model(x)\n",
    "        # Step 2 - Computes the loss\n",
    "        loss = loss_fn(y, yhat)\n",
    "        # Step 3 - Computes gradients for both \"a\" and \"b\" parameters\n",
    "        loss.backward()\n",
    "        # Step 4 - Updates parameters using gradients and the learning rate\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    # Returns the function that will be called inside the train loop\n",
    "    return perform_train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v1.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"a\" and \"b\" randomly\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.make_train_step.<locals>.perform_train_step(x, y)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v1.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # Performs one train step and returns the corresponding loss\n",
    "    loss = train_step(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9690]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.1196],\n",
       "         [0.1395],\n",
       "         [0.2809],\n",
       "         [0.1834],\n",
       "         [0.3585],\n",
       "         [0.5427],\n",
       "         [0.0885],\n",
       "         [0.9489],\n",
       "         [0.9699],\n",
       "         [0.7751],\n",
       "         [0.9696],\n",
       "         [0.7320],\n",
       "         [0.0055],\n",
       "         [0.7069],\n",
       "         [0.8155],\n",
       "         [0.5979]]), tensor([[1.3214],\n",
       "         [1.3051],\n",
       "         [1.5846],\n",
       "         [1.4637],\n",
       "         [1.7462],\n",
       "         [2.2161],\n",
       "         [1.0708],\n",
       "         [2.8903],\n",
       "         [2.9727],\n",
       "         [2.4936],\n",
       "         [2.8401],\n",
       "         [2.4732],\n",
       "         [1.0632],\n",
       "         [2.4388],\n",
       "         [2.6606],\n",
       "         [2.0407]])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v1.py\n",
    "\n",
    "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "# Builds Dataset\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "# Builds DataLoader\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v2.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
    "        # therefore, we need to send those mini-batches to the\n",
    "        # device where the model \"lives\"\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Performs one train step and returns the corresponding loss \n",
    "        # for this mini-batch\n",
    "        mini_batch_loss = train_step(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    # Computes average loss over all mini-batches - that's the epoch loss\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    \n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9684]], device='cuda:0')), ('0.bias', tensor([1.0235], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch Inner Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(device, data_loader, step):\n",
    "    mini_batch_losses = []\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = step(x_batch, y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py\n",
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v3.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9687]], device='cuda:0')), ('0.bias', tensor([1.0236], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_preparation/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performs the split\n",
    "train_data, val_data = random_split(dataset, [80, 20])\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_val_step(model, loss_fn):\n",
    "    # Builds function that performs a step in the validation loop\n",
    "    def perform_val_step(x, y):\n",
    "        # Sets model to EVAL mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Step 1 - Computes our model's predicted output - forward pass\n",
    "        yhat = model(x)\n",
    "        # Step 2 - Computes the loss\n",
    "        loss = loss_fn(y, yhat)\n",
    "        # There is no need to compute Steps 3 and 4, since we don't update parameters during evaluation\n",
    "        return loss.item()\n",
    "    \n",
    "    return perform_val_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v2.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"a\" and \"b\" randomly\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Creates the val_step function for our model and loss function\n",
    "val_step = make_val_step(model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v4.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # VALIDATION\n",
    "    # no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step)\n",
    "        val_losses.append(val_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9440]], device='cuda:0')), ('0.bias', tensor([1.0249], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/projects/PyTorchStepByStep/model_training/v4.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    856\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    857\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m                             check_tolerance, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;31m# this is needed since Module.__call__ sets up some extra tracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mmake_tuple\u001b[0;34m(example_inputs)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# done primarily so that weird iterables fail here and not pybind11 code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "writer.add_graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching a tuple of feature (sample_x) and label (sample_y)\n",
    "sample_x, sample_y = next(iter(train_loader))\n",
    "\n",
    "# Since our model was sent to device, we need to do the same with the data\n",
    "# Even here, both model and data need to be on the same device!\n",
    "writer.add_graph(model, sample_x.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add_scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalars('loss', {'training': loss, 'validation': val_loss}, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_configuration/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v3.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"a\" and \"b\" randomly\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Creates the val_step function for our model and loss function\n",
    "val_step = make_val_step(model, loss_fn)\n",
    "\n",
    "# Creates a Summary Writer to interface with TensorBoard\n",
    "writer = SummaryWriter('runs/simple_linear_regression')\n",
    "\n",
    "# Fetches a single mini-batch so we can use add_graph\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "writer.add_graph(model, x_sample.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v5.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # VALIDATION\n",
    "    # no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    # Records both losses for each epoch under the main tag \"loss\"\n",
    "    writer.add_scalars(main_tag='loss',\n",
    "                       tag_scalar_dict={'training': loss, 'validation': val_loss},\n",
    "                       global_step=epoch)\n",
    "\n",
    "# Closes the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9440]], device='cuda:0')), ('0.bias', tensor([1.0249], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'epoch': n_epochs,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "              'loss': losses,\n",
    "              'val_loss': val_losses}\n",
    "\n",
    "torch.save(checkpoint, 'model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "losses = checkpoint['loss']\n",
    "val_losses = checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9440]], device='cuda:0')), ('0.bias', tensor([1.0249], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load data_preparation/v2.py\n",
    "\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Builds tensors from numpy arrays BEFORE split\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "# Builds dataset containing ALL data points\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# Performs the split\n",
    "train_data, val_data = random_split(dataset, [80, 20])\n",
    "\n",
    "# Builds a loader of each set\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_configuration/v3.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Sets learning rate - this is \"eta\" ~ the \"n\" like Greek letter\n",
    "lr = 0.1\n",
    "\n",
    "# Step 0 - Initializes parameters \"a\" and \"b\" randomly\n",
    "torch.manual_seed(42)\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "\n",
    "# Defines a SGD optimizer to update the parameters (now retrieved directly from the model)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# Defines a MSE loss function\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "\n",
    "# Creates the val_step function for our model and loss function\n",
    "val_step = make_val_step(model, loss_fn)\n",
    "\n",
    "# Creates a Summary Writer to interface with TensorBoard\n",
    "writer = SummaryWriter('runs/simple_linear_regression')\n",
    "\n",
    "# Fetches a single mini-batch so we can use add_graph\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "writer.add_graph(model, x_sample.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model_training/v5.py\n",
    "\n",
    "# Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # VALIDATION\n",
    "    # no gradients in validation!\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device, val_loader, val_step)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    # Records both losses for each epoch under the main tag \"loss\"\n",
    "    writer.add_scalars(main_tag='loss',\n",
    "                       tag_scalar_dict={'training': loss, 'validation': val_loss},\n",
    "                       global_step=epoch)\n",
    "\n",
    "# Closes the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9440]], device='cuda:0')), ('0.bias', tensor([1.0249], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
